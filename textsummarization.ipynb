{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 02:15:02.936973: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-27 02:15:04.075415: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {DEVICE} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/ciprian/Pythonvscode/Pythonprograms/samsum-test.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure the CSV contains the expected columns\n",
    "assert 'dialogue' in df.columns and 'summary' in df.columns, \"The CSV file must contain 'dialogue' and 'summary' columns\"\n",
    "df = df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to match the expected format in the rest of the script\n",
    "df = df.rename(columns={'dialogue': 'src', 'summary': 'trg'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['src_len'] = [len(text.split()) for text in df.src]\n",
    "df['trg_len'] = [len(text.split()) for text in df.trg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>trg</th>\n",
       "      <th>src_len</th>\n",
       "      <th>trg_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hannah: Hey, do you have Betty's number?\\nAman...</td>\n",
       "      <td>Hannah needs Betty's number but Amanda doesn't...</td>\n",
       "      <td>71</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eric: MACHINE!\\r\\nRob: That's so gr8!\\r\\nEric:...</td>\n",
       "      <td>Eric and Rob are going to watch a stand-up on ...</td>\n",
       "      <td>82</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenny: Babe, can you help me with something?\\r...</td>\n",
       "      <td>Lenny can't decide which trousers to buy. Bob ...</td>\n",
       "      <td>106</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Will: hey babe, what do you want for dinner to...</td>\n",
       "      <td>Emma will be home soon and she will let Will k...</td>\n",
       "      <td>85</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ollie: Hi , are you in Warsaw\\r\\nJane: yes, ju...</td>\n",
       "      <td>Jane is in Warsaw. Ollie and Jane has a party....</td>\n",
       "      <td>207</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 src  \\\n",
       "0  Hannah: Hey, do you have Betty's number?\\nAman...   \n",
       "1  Eric: MACHINE!\\r\\nRob: That's so gr8!\\r\\nEric:...   \n",
       "2  Lenny: Babe, can you help me with something?\\r...   \n",
       "3  Will: hey babe, what do you want for dinner to...   \n",
       "4  Ollie: Hi , are you in Warsaw\\r\\nJane: yes, ju...   \n",
       "\n",
       "                                                 trg  src_len  trg_len  \n",
       "0  Hannah needs Betty's number but Amanda doesn't...       71       14  \n",
       "1  Eric and Rob are going to watch a stand-up on ...       82       11  \n",
       "2  Lenny can't decide which trousers to buy. Bob ...      106       27  \n",
       "3  Emma will be home soon and she will let Will k...       85       11  \n",
       "4  Jane is in Warsaw. Ollie and Jane has a party....      207       42  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def src_preprocessing(data, col):\n",
    "    data[col] = data[col].astype(str)\n",
    "    data[col] = data[col].apply(lambda x: x.lower())\n",
    "    data[col] = data[col].apply(lambda x: re.sub(\"[^A-Za-z\\s]\", \"\", x))\n",
    "    data[col] = data[col].apply(lambda x: re.sub(\"\\s+\", \" \", x))\n",
    "    data[col] = data[col].apply(lambda x: \" \".join([word for word in x.split()]))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trg_preprocessing(data, col):\n",
    "    data[col] = data[col].astype(str)\n",
    "    data[col] = data[col].apply(lambda x: x.lower())\n",
    "    data[col] = data[col].apply(lambda x: re.sub(r'\\d', '', x))\n",
    "    data[col] = data[col].apply(lambda x: re.sub(r'\\s+', ' ', x))\n",
    "    data[col] = data[col].apply(lambda x: re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,।]\", \"\", x))\n",
    "    data[col] = data[col].apply(lambda x: x.strip())\n",
    "    data[col] = \"<sos> \" + data[col] + \" <eos>\"\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = src_preprocessing(df, 'src')\n",
    "df = trg_preprocessing(df, 'trg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering based on summarization length criteria\n",
    "df = df[~(df['src_len'] < 50) & ~(df['src_len'] > 300)]\n",
    "df = df[~(df['trg_len'] < 10) & ~(df['trg_len'] > 50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_MAXLEN = np.max(df['src_len'])\n",
    "TRG_MAXLEN = np.max(df['trg_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vectorization(col, MAXLEN):\n",
    "    sents = df[col].tolist()\n",
    "    corpus = [word for text in df[col] for word in text.split()]\n",
    "    vocab_size = len(Counter(corpus))\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\",\n",
    "                          filters='!#$%&()*+,-/:;<=>@«»\"\"[\\\\]^_`{|}~\\t\\n')\n",
    "\n",
    "    tokenizer.fit_on_texts(sents)\n",
    "    tokenizer.word_index['<pad>'] = 0\n",
    "    tokenizer.index_word[0] = '<pad>'\n",
    "\n",
    "    # Ensure special tokens are in the tokenizer\n",
    "    if '<sos>' not in tokenizer.word_index:\n",
    "        tokenizer.word_index['<sos>'] = len(tokenizer.word_index) + 1\n",
    "        tokenizer.index_word[tokenizer.word_index['<sos>']] = '<sos>'\n",
    "    if '<eos>' not in tokenizer.word_index:\n",
    "        tokenizer.word_index['<eos>'] = len(tokenizer.word_index) + 1\n",
    "        tokenizer.index_word[tokenizer.word_index['<eos>']] = '<eos>'\n",
    "\n",
    "    seqs = tokenizer.texts_to_sequences(sents)\n",
    "    pad_seqs = pad_sequences(seqs, maxlen=MAXLEN, padding='post')\n",
    "\n",
    "    return pad_seqs, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_seqs, src_tokenizer = Vectorization('src', SRC_MAXLEN)\n",
    "trg_seqs, trg_tokenizer = Vectorization('trg', TRG_MAXLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the source vocab size: 5664\n",
      "\n",
      "The size of the target vocab size: 2870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"The size of the source vocab size: {len(src_tokenizer.word_index)}\\n\")\n",
    "print(f\"The size of the target vocab size: {len(trg_tokenizer.word_index)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2  724   16   42  510  156   20 1223  183  136   99   10    7  383\n",
      "    4    7  725   17   39  726   38 1224  306   61   29   14  124  212\n",
      "   12    6  510  107    3    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0] \n",
      "\n",
      " sos gloria has an exam soon it lasts hours emma sent her a link to a website with some texts from previous years so that she can prepare for the exam better eos\n"
     ]
    }
   ],
   "source": [
    "trg_sent = ' '.join([trg_tokenizer.index_word[idx] for idx in trg_seqs[15] if idx != 0])\n",
    "print(f\"{trg_seqs[15]} \\n\\n {trg_sent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = TensorDataset(torch.LongTensor(src_seqs), torch.LongTensor(trg_seqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "ds_dataloader = DataLoader(\n",
    "    dataset=ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the dataloader 8 batches of 64\n"
     ]
    }
   ],
   "source": [
    "print(f\"The size of the dataloader {len(ds_dataloader)} batches of {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>6 <span style='color:#9146ff'>|</span> Build our model</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='font-size:25px;font-weight:bold;color:#9146ff'><b style='color:black'>1-</b> Self Attention</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SelfAttention(q, k, v, mask):\n",
    "    attention_logits = torch.matmul(q, k.transpose(-2, -1)).to(DEVICE)\n",
    "    scaling = torch.sqrt(torch.tensor(k.size(-1), dtype=torch.float32)).to(DEVICE)\n",
    "    scaled_attention_logits = attention_logits / scaling\n",
    "\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "    attention_weights = torch.softmax(scaled_attention_logits, dim=-1).to(DEVICE)\n",
    "    output = torch.matmul(attention_weights, v).to(DEVICE)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='font-size:25px;font-weight:bold;color:#9146ff'><b style='color:black'>2-</b> Multi-Head Attention</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        assert self.embedding_dim % self.num_heads == 0\n",
    "\n",
    "        self.head_dim = self.embedding_dim // self.num_heads\n",
    "\n",
    "        self.queries = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.keys = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.values = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.fc_out = nn.Linear(embedding_dim, embedding_dim)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = x.reshape(batch_size, -1, self.num_heads, self.head_dim)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        batch_size = q.shape[0]\n",
    "\n",
    "        q = self.queries(q)\n",
    "        k = self.keys(k)\n",
    "        v = self.values(v)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "\n",
    "        scaled_attention = SelfAttention(q, k, v, mask)\n",
    "\n",
    "        scaled_attention = scaled_attention.permute(0, 2, 1, 3)\n",
    "        attention_output = scaled_attention.reshape(batch_size, -1, self.embedding_dim)\n",
    "\n",
    "        out = self.fc_out(attention_output)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='font-size:25px;font-weight:bold;color:#9146ff'><b style='color:black'>3-</b> Encoder</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_heads, fc_dim, dropout_rate=0.1):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "\n",
    "        self.MHA = MultiHeadAttention(embedding_dim, num_heads)\n",
    "        self.norm1 = nn.LayerNorm(embedding_dim, eps=1e-6)\n",
    "        self.norm2 = nn.LayerNorm(embedding_dim, eps=1e-6)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, fc_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(fc_dim, embedding_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        attn_out = self.MHA(x, x, x, mask)\n",
    "        attn_out = self.dropout1(attn_out)\n",
    "        out1 = self.norm1(x + attn_out)\n",
    "\n",
    "        fc_out = self.dropout2(self.fc(out1))\n",
    "        enc_out = self.norm2(out1 + fc_out)\n",
    "\n",
    "        return enc_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_layers, embedding_dim, num_heads, fc_dim, src_vocab_size, max_length, dropout_rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(src_vocab_size, embedding_dim)\n",
    "        self.pos_encoding = nn.Embedding(max_length, embedding_dim)\n",
    "        self.enc_layers = [EncoderBlock(embedding_dim, num_heads, fc_dim, dropout_rate).to(DEVICE) for _ in range(num_layers)]\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        batch_size, seqlen = x.shape\n",
    "        positions = torch.arange(0, seqlen).expand(batch_size, seqlen).to(DEVICE)\n",
    "        out = self.dropout((self.embedding(x) + self.pos_encoding(positions)))\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            out = self.enc_layers[i](out, mask)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='font-size:25px;font-weight:bold;color:#9146ff'><b style='color:black'>4-</b> Decoder</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_heads, fc_dim, dropout_rate=0.1):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "\n",
    "        self.MHA1 = MultiHeadAttention(embedding_dim, num_heads)\n",
    "        self.MHA2 = MultiHeadAttention(embedding_dim, num_heads)\n",
    "        self.norm1 = nn.LayerNorm(embedding_dim, eps=1e-6)\n",
    "        self.norm2 = nn.LayerNorm(embedding_dim, eps=1e-6)\n",
    "        self.norm3 = nn.LayerNorm(embedding_dim, eps=1e-6)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.dropout3 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, fc_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(fc_dim, embedding_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        attn1 = self.MHA1(x, x, x, look_ahead_mask)\n",
    "        attn1 = self.dropout1(attn1)\n",
    "        out1 = self.norm1(attn1 + x)\n",
    "\n",
    "        attn2 = self.MHA2(out1, enc_output, enc_output, padding_mask)\n",
    "        attn2 = self.dropout2(attn2)\n",
    "        out2 = self.norm2(attn2 + out1)\n",
    "\n",
    "        fc_out = self.dropout3(self.fc(out2))\n",
    "        dec_out = self.norm3(fc_out + out2)\n",
    "\n",
    "        return dec_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_layers, embedding_dim, num_heads, fc_dim, trg_vocab_size, max_length, dropout_rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(trg_vocab_size, embedding_dim)\n",
    "        self.pos_encoding = nn.Embedding(max_length, embedding_dim)\n",
    "        self.dec_layers = [DecoderBlock(embedding_dim, num_heads, fc_dim, dropout_rate).to(DEVICE) for _ in range(num_layers)]\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        batch_size, seqlen = x.shape\n",
    "        positions = torch.arange(0, seqlen).expand(batch_size, seqlen).to(DEVICE)\n",
    "        out = self.dropout((self.embedding(x) + self.pos_encoding(positions)))\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            out = self.dec_layers[i](out, enc_output, look_ahead_mask, padding_mask)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, num_layers, embedding_dim, num_heads, fc_dim, src_vocab_size, trg_vocab_size, src_max_length, trg_max_length, dropout_rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(\n",
    "            num_layers,\n",
    "            embedding_dim,\n",
    "            num_heads,\n",
    "            fc_dim,\n",
    "            src_vocab_size,\n",
    "            src_max_length,\n",
    "            dropout_rate\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        self.decoder = Decoder(\n",
    "            num_layers,\n",
    "            embedding_dim,\n",
    "            num_heads,\n",
    "            fc_dim,\n",
    "            trg_vocab_size,\n",
    "            trg_max_length,\n",
    "            dropout_rate\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        self.fc_out = nn.Linear(embedding_dim, trg_vocab_size)\n",
    "\n",
    "    def padding_mask(self, seq):\n",
    "        seq_mask = (seq == 0).float().unsqueeze(1).unsqueeze(2)\n",
    "        return seq_mask\n",
    "\n",
    "    def look_ahead_mask(self, trg):\n",
    "        batch_size, trg_len = trg.shape\n",
    "        trg_mask = 1 - torch.tril(torch.ones((trg_len, trg_len)), diagonal=0).expand(\n",
    "            batch_size, 1, trg_len, trg_len\n",
    "        )\n",
    "        return trg_mask\n",
    "\n",
    "    def create_masks(self, src, trg):\n",
    "        enc_padding_mask = self.padding_mask(src).to(DEVICE)\n",
    "        dec_padding_mask = self.padding_mask(src).to(DEVICE)\n",
    "        look_ahead_mask = self.look_ahead_mask(trg).to(DEVICE)\n",
    "        dec_trg_padding_mask = self.padding_mask(trg).to(DEVICE)\n",
    "        combined_mask = torch.max(dec_trg_padding_mask, look_ahead_mask).to(DEVICE)\n",
    "\n",
    "        return enc_padding_mask, combined_mask, dec_padding_mask\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        enc_padding_mask, look_ahead_mask, dec_padding_mask = self.create_masks(src, trg)\n",
    "        enc_output = self.encoder(src, enc_padding_mask)\n",
    "        dec_output = self.decoder(trg, enc_output, look_ahead_mask, dec_padding_mask)\n",
    "        out = self.fc_out(dec_output)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "EPOCHS = 200\n",
    "LR = 1e-3\n",
    "EMBEDDING_DIM = 128\n",
    "FC_DIM = 512\n",
    "NUM_LAYERS = 4\n",
    "NUM_HEADS = 8\n",
    "DROPOUT_RATE = 0.1\n",
    "SRC_VOCAB_SIZE = len(src_tokenizer.word_index)\n",
    "TRG_VOCAB_SIZE = len(trg_tokenizer.word_index)\n",
    "\n",
    "model = Transformer(\n",
    "    NUM_LAYERS,\n",
    "    EMBEDDING_DIM,\n",
    "    NUM_HEADS,\n",
    "    FC_DIM,\n",
    "    SRC_VOCAB_SIZE,\n",
    "    TRG_VOCAB_SIZE,\n",
    "    SRC_MAXLEN,\n",
    "    TRG_MAXLEN,\n",
    "    DROPOUT_RATE\n",
    ").to(DEVICE)\n",
    "\n",
    "temp_src = torch.randint(low=0, high=200, size=(BATCH_SIZE, SRC_MAXLEN), dtype=torch.int64).to(DEVICE)\n",
    "temp_trg = torch.randint(low=0, high=200, size=(BATCH_SIZE, TRG_MAXLEN), dtype=torch.int64).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 50, 2870])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_trg_out = model(temp_src, temp_trg)\n",
    "temp_trg_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Transformer                              [64, 50, 2870]            --\n",
       "├─Encoder: 1-1                           [64, 299, 128]            --\n",
       "│    └─Embedding: 2-1                    [64, 299, 128]            724,992\n",
       "│    └─Embedding: 2-2                    [64, 299, 128]            38,272\n",
       "│    └─Dropout: 2-3                      [64, 299, 128]            --\n",
       "├─Decoder: 1-2                           [64, 50, 128]             --\n",
       "│    └─Embedding: 2-4                    [64, 50, 128]             367,360\n",
       "│    └─Embedding: 2-5                    [64, 50, 128]             6,400\n",
       "│    └─Dropout: 2-6                      [64, 50, 128]             --\n",
       "├─Linear: 1-3                            [64, 50, 2870]            370,230\n",
       "==========================================================================================\n",
       "Total params: 1,507,254\n",
       "Trainable params: 1,507,254\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 96.46\n",
       "==========================================================================================\n",
       "Input size (MB): 0.18\n",
       "Forward/backward pass size (MB): 119.22\n",
       "Params size (MB): 6.03\n",
       "Estimated Total Size (MB): 125.42\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_data=[temp_src, temp_trg])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>7 <span style='color:#9146ff'>|</span> Train our model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=src_tokenizer.word_index['<pad>'])\n",
    "optimizer = Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(src, trg):\n",
    "    decoder_input = trg[:, :-1]\n",
    "    trg_reals = trg[:, 1:].reshape(-1)\n",
    "    preds = model(src, decoder_input)\n",
    "    preds = preds.reshape(-1, preds.shape[2])\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(preds, trg_reals)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "    optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m src, trg \u001b[38;5;129;01min\u001b[39;00m ds_dataloader:\n\u001b[1;32m      6\u001b[0m     src, trg \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mto(DEVICE), trg\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m----> 7\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m      9\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend((epoch_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(ds_dataloader))\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "Cell \u001b[0;32mIn[31], line 8\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(src, trg)\u001b[0m\n\u001b[1;32m      6\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      7\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(preds, trg_reals)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/Pythonvscode/Learningpython/lib/python3.12/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Pythonvscode/Learningpython/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Pythonvscode/Learningpython/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    epoch_loss = 0\n",
    "    model.train()\n",
    "    for src, trg in ds_dataloader:\n",
    "        src, trg = src.to(DEVICE), trg.to(DEVICE)\n",
    "        loss = train_step(src, trg)\n",
    "        epoch_loss += loss\n",
    "    train_losses.append((epoch_loss / len(ds_dataloader)).cpu().detach().numpy())\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(f\"\\n[Epoch :  {epoch+1}/{EPOCHS}] [Train Loss : {train_losses[-1]:0.2f}]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x77246a272bd0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='train')\n",
    "plt.title('Training loss over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>8 <span style='color:#9146ff'>|</span> Evaluate</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sent):\n",
    "    sentence = src_tokenizer.texts_to_sequences([sent])\n",
    "    sentence = pad_sequences(sentence, maxlen=SRC_MAXLEN, padding='post')\n",
    "    src_input = torch.tensor(np.array(sentence), dtype=torch.int64)\n",
    "    decoder_input = trg_tokenizer.texts_to_sequences(['<sos>'])\n",
    "    decoder_input = torch.tensor(np.array(decoder_input), dtype=torch.int64)\n",
    "    src_input, decoder_input = src_input.to(DEVICE), decoder_input.to(DEVICE)\n",
    "\n",
    "    for i in range(TRG_MAXLEN):\n",
    "        preds = model(src_input, decoder_input)\n",
    "        preds = preds[:, -1:, :]\n",
    "        predicted_id = torch.argmax(preds, dim=-1)\n",
    "        if predicted_id.item() == trg_tokenizer.word_index['<eos>']:\n",
    "            return decoder_input.squeeze(0)\n",
    "        decoder_input = torch.cat([decoder_input, predicted_id], dim=1)\n",
    "\n",
    "    return decoder_input.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = df.sample(100)\n",
    "x_test = test_sample['src'].tolist()\n",
    "y_test = test_sample['trg'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence 1 : dima hello nada hey girl whats up dima im in a huge trouble my laptop is broken and i have to deliver a translation tomorrow nada fuck what happened dima the stupid cat spilled coffee on it im freaking out dima you still have your old laptop is it possible to lend it to me please nada no sorry ive given it to my brother but youre lucky ive taken these two days off so you can take mine dima ooh man thank you sooo much if it werent for trados i wouldnt be panicking nada no worries it happened but i always think about this like man we need some back up laptops dima i know but i always change my mind and spend the money elsewhere lol nada yeah but its like our only tool so we need to invest in it dima yup true dima can i come in an hour to pick it up nada yes ttyl\n",
      "Actual summary 1 : <sos> dima's laptop is broken as her cat spilled coffee on the laptop dima is worried because she has to deliver a translation for trados tomorrow dima will come to nada in an hour to borrow nada's laptop <eos>\n",
      "Predicted summary 1 : jane and john are going to the gym and she will be hospitalised the desert will come to the base eos eos her eos eos eos eos eos and brown shoes will be fine will meet at work eos eos eos eos eos will be home eos appreciated the same\n",
      "\n",
      "Input sentence 2 : jason yo what are you doing after work mike going to the gym and then home boy jason you eating at home mike yep bring your food and come over jason will do afterwards we play some destiny on ps mike you bet ya that game is so addictive jason ok cya later then mike oh yeah\n",
      "Actual summary 2 : <sos> after work mike is going to go to the gym and then home he invites jason to bring some food and come over they can play on ps <eos>\n",
      "Predicted summary 2 : kate is going to the party and he will be eos to the zoo eos eos her facebook posts a new clients eos eos eos eos eos eos eos eos to the reception eos to the lily's eos eos eos eos eos to the different vibe the th and george\n",
      "\n",
      "Input sentence 3 : henny filegif henny dear frances something beautiful and funny for a good new year frances it is so wonderful thank you frances for you too all the best in frances filephoto henny thanks a lovely view is it near you frances am just back from the vosges it was a view we had from our sitting room the farm house turned into a holiday flat was just superb here a few pics frances filephoto henny that looks superb far from maddening crowd frances thats it absolutely quiet no banging on the new years eve no busy roads henny so aiden was a happy dog frances totally ferdinand too we the tree of us had a great week there and didnt even spend much money henny did you cook frances partly ferdinand but we also had meals in a local was exceptionally tasty henny duce france frances cest ca\n",
      "Actual summary 3 : <sos> frances just got back from vosges she stayed a week in a farm house with ferdinand and her dog aiden <eos>\n",
      "Predicted summary 3 : kate is going to go to the gym and he is coming eos her eos eos her eos to the butt the whole album eos eos eos eos eos eos eos eos eos eos eos after work eos eos eos eos eos to the weekend eos the th and she\n",
      "\n",
      "Input sentence 4 : avery you went to ethans house david yeah i had to babysit avery aww how do you babysit just curious david i had to go through a lot avery was his sister naughty david tooo much avery lol david i will just refuse net time avery as you wish david avery i just got his text david what is he saying avery he is asking me to say thanks to you david yeah whatever avery he was saying that your phone was switched off david yeah i have just turned it on avery i have told him about that david k avery gotta go now\n",
      "Actual summary 4 : <sos> david was looking after ethan's sister ethan is grateful david won't do it again <eos>\n",
      "Predicted summary 4 : rob is going to go to the gym and he is going to the photoshoot cristina prefers wednesdays the notes eos eos eos eos eos eos eos eos eos eos eos eos eos eos to the lily's eos eos eos eos eos to the th eos eos appreciated the gym\n",
      "\n",
      "Input sentence 5 : ethan whos going to see solstafir noah solstafir when noah i had no idea they were playing archie im not d leo im going ofc ethan noah thats a wednesday ehh noah ill have to see might have to stay late at work leo nooo you have to come ethan yeah you have to archie there are better concerts p noah i know i would really like to see them but yeah leo archie p ethan dont mind him p noah ill see and let you know it would really suck to miss them leo yup ethan yup x\n",
      "Actual summary 5 : <sos> ethan and leo are going to see sólstafir on  noah would like to go too but he might have to stay late at work <eos>\n",
      "Predicted summary 5 : kate is going to go to the gym mair a new sofa eos eos eos eos her eos eos her eos eos eos eos eos eos eos eos eos eos eos eos eos eos to the lily's eos eos eos eos eos to the th eos eos appreciated the door\n",
      "\n",
      "Input sentence 6 : frank wat are u doing andy watching arrow b frank dont u have a quiz tomorrow andy yeah so frank so go study for it andy its a small quiz frank so it doesnot matter andy it does but frank but andy ill study for it tomorrow frank yea like ur gonna wake up on time for that andy dude your not my dad frank\n",
      "Actual summary 6 : <sos> frank tries to encourage andy to learn for the tomorrow's quiz <eos>\n",
      "Predicted summary 6 : jane and john are going to the weekend dory's in the slimming eos eos eos eos her facebook posts her eos eos eos eos eos eos eos eos and brown shoes eos eos eos eos her mum eos eos eos eos eos eos eos different vibe the th eos eos\n",
      "\n",
      "Input sentence 7 : ann hello katie thank you so much for hosting tim monday evening and for dropping him at the railway station next morning here is mobile number i ll confirm you but again and in advance thanks a lot katie hello ann i didnt realise but we spend a week end together years ago in saint fargeau ann it goes back so long but its possible ann its true that i know ben since school katie as far as im concern i remember very well this week end as i had a very good friends call ann cairns like you eriks wife ann eriks wife of course hes my cousin and ann his wife is the cousin of one of my best friend small word katie indeed ann hi katie is it still ok for hosting my son tomorrow you may send him a text to tell him where you want to pick him up thanks so much katie yes ann ill send a text to your son for tomorrow ann thanks funny you also know stef and leo friends of us in berlin but its true they lived in reims before katie your son is really nice dont hesitate to contact me again if needed\n",
      "Actual summary 7 : <sos> ann thanks katie for hosting her son tim on monday evening and driving him to the railway station next morning kate will send a message to tim tomorrow to ask about the place where she should be waiting for him <eos>\n",
      "Predicted summary 7 : rob is going to go to buy a birthday a few videos her the photoshoot the gym and it eos eos on the office and it eos eos eos eos eos eos eos to borrow nada's the zoo eos eos eos eos to the with eos eos appreciated the th\n",
      "\n",
      "Input sentence 8 : mike how did chicago do last nite pat chicago what mike fire man pat dunno mike how come pat its soccer right mike you not a soccer fan pat nah baseball and hockey is wot i luv mike its bears and white sox right pat bears is football white sox is baseball mike and hockey pat blackhawks but not doing well right now mike and bulls used to be better too i guess pat true enough jordan times long gone mike u fancy hoops at all pat not really not now mike u play tho pat yeah i still hit points well enough mike i like to play sometime pat good idea we need to do meet up one day mike yeah always good to hit the ball\n",
      "Actual summary 8 : <sos> pat is interested in baseball and hockey he doesn't know much about basketball anymore he plans to play basketball with mike one day <eos>\n",
      "Predicted summary 8 : jane and john are going to the gym mair a new sofa eos to the second hand shop downtown her injury ola at the government eos eos eos eos eos eos eos eos eos to the lily's eos eos eos eos eos to the different vibe the th eos eos\n",
      "\n",
      "Input sentence 9 : sophia im sorry mason its fine sophia okif u was there i would give you a hot kiss for apologize mason hahaha you still send me a photo one sophia what photo mason kiss photo haha sophia hehe i sent u already such a photo mason another one wouldnt hurt sophia maybe later when i take a shower and look good mason and who says you dont look good now sophia me mason let me be the judge of that sophia no mason ill still love you the same whether you have make up or not sophia hehe but i dont want u to see me when i do not look good mason you must sophia i must what mason send me the kiss now sophia haha mason doesnt matter how you look youll still look good to me sophia hahah sophia filephoto\n",
      "Actual summary 9 : <sos> sophia apologizes to mason she sends him a kiss photo on his request <eos>\n",
      "Predicted summary 9 : kate is going to go to the gym the weekend eos to the story to go to get it eos eos eos eos to the hulu eos eos eos eos eos eos eos eos to the lily's eos eos eos eos eos to the different vibe the th and is\n",
      "\n",
      "Input sentence 10 : joanne what are your plans for the holidays evelyn nothing ill stay at home and rest joanne you must be exhausted after the past few weeks evelyn its been hectic joanne im going back home evelyn to france joanne yes not that i want to go evelyn why you always liked spending christmas with your family joanne i did but my parents separated a few months ago joanne it is still pretty tense evelyn im sorry to hear that joanne my dad left my mum for his secretary joanne such a clich joanne my mum is devastated joanne so im basically going to cheer her up joanne its really hard for her now joanne for me its also not easy evelyn i can imagine evelyn if you want to bring your mum over here we could spend christmas together joanne thanks thats really sweet but i dont think shes in a condition for that shes been very depressive lately\n",
      "Actual summary 10 : <sos> joanne is going to go back home to france for the holidays she's going to cheer her mum up because her parents separated a few months ago evelyn offers joanne to spend christmas together if she brings her mum over here <eos>\n",
      "Predicted summary 10 : there is going to go to the gym mair a new sofa eos eos eos eos eos eos eos her eos to the office and jada eos eos eos eos to the reception eos to the lily's eos eos eos eos eos to the different vibe the th and he\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, (src_sent, trg_sent) in enumerate(zip(x_test[-10:], y_test[-10:])):\n",
    "    result = evaluate(src_sent)\n",
    "    pred_sent = ' '.join([trg_tokenizer.index_word[idx] for idx in result.cpu().numpy() if idx != 0 and idx != 2])\n",
    "    print(f\"Input sentence {idx+1} : {src_sent}\")\n",
    "    print(f\"Actual summary {idx+1} : {trg_sent}\")\n",
    "    print(f\"Predicted summary {idx+1} : {pred_sent}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Learningpython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
